{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import pandas as pd\n",
        "from azure.ai.ml.entities import Environment\n",
        "from azure.ai.ml import command\n",
        "import mlflow\n",
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1761853594928
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiendo autenticacion, debes poner tus credenciales en las variables\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51\",\n",
        "    resource_group_name=\"brazilian-ecommerce-sentiment-analysis\",\n",
        "    workspace_name=\"sentiment-analysis\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1761842572662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asset_reviews = ml_client.data.get(\"olist_order_reviews\", version=\"1\")\n",
        "asset_orders_full = ml_client.data.get('orders_full_imputed', version='1')\n",
        "order_reviews = pd.read_csv(asset_reviews.path)\n",
        "orders_full_imputed = pd.read_csv(asset_orders_full.path)\n",
        "orders_full_imputed"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nOverriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_score</th>\n      <th>item_price_mean</th>\n      <th>freight_value_mean</th>\n      <th>total_payment</th>\n      <th>n_items</th>\n      <th>unique_items</th>\n      <th>unique_sellers</th>\n      <th>payment_type</th>\n      <th>product_category</th>\n      <th>product_weight_g_sum</th>\n      <th>...</th>\n      <th>delivery_delay_days</th>\n      <th>purchase_month</th>\n      <th>shipping_delay_days</th>\n      <th>seller_lat</th>\n      <th>seller_lng</th>\n      <th>customer_lat</th>\n      <th>customer_lng</th>\n      <th>lat_diff</th>\n      <th>lng_diff</th>\n      <th>geo_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>58.90</td>\n      <td>13.29</td>\n      <td>72.19</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>cool_stuff</td>\n      <td>650</td>\n      <td>...</td>\n      <td>-9</td>\n      <td>9</td>\n      <td>0</td>\n      <td>-22.496953</td>\n      <td>-44.127492</td>\n      <td>-21.762775</td>\n      <td>-41.309633</td>\n      <td>-0.734177</td>\n      <td>-2.817859</td>\n      <td>2.911932</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>239.90</td>\n      <td>19.93</td>\n      <td>259.83</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>pet_shop</td>\n      <td>30000</td>\n      <td>...</td>\n      <td>-3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-23.565096</td>\n      <td>-46.518565</td>\n      <td>-20.220527</td>\n      <td>-50.903424</td>\n      <td>-3.344569</td>\n      <td>4.384859</td>\n      <td>5.514810</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>199.00</td>\n      <td>17.87</td>\n      <td>216.87</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>furniture_decor</td>\n      <td>3050</td>\n      <td>...</td>\n      <td>-14</td>\n      <td>1</td>\n      <td>-3</td>\n      <td>-22.262584</td>\n      <td>-46.171124</td>\n      <td>-19.870305</td>\n      <td>-44.593326</td>\n      <td>-2.392279</td>\n      <td>-1.577798</td>\n      <td>2.865737</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>12.99</td>\n      <td>12.79</td>\n      <td>25.78</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>perfumery</td>\n      <td>200</td>\n      <td>...</td>\n      <td>-6</td>\n      <td>8</td>\n      <td>-5</td>\n      <td>-20.553624</td>\n      <td>-47.387359</td>\n      <td>-23.089925</td>\n      <td>-46.611654</td>\n      <td>2.536302</td>\n      <td>-0.775705</td>\n      <td>2.652271</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>199.90</td>\n      <td>18.14</td>\n      <td>218.04</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>garden_tools</td>\n      <td>3750</td>\n      <td>...</td>\n      <td>-16</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-22.929384</td>\n      <td>-53.135873</td>\n      <td>-23.243402</td>\n      <td>-46.827614</td>\n      <td>0.314018</td>\n      <td>-6.308258</td>\n      <td>6.316069</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>98668</th>\n      <td>5</td>\n      <td>299.99</td>\n      <td>43.41</td>\n      <td>343.40</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>boleto</td>\n      <td>housewares</td>\n      <td>10150</td>\n      <td>...</td>\n      <td>-8</td>\n      <td>4</td>\n      <td>-7</td>\n      <td>-26.912574</td>\n      <td>-48.673980</td>\n      <td>-2.497993</td>\n      <td>-44.297761</td>\n      <td>-24.414581</td>\n      <td>-4.376219</td>\n      <td>24.803690</td>\n    </tr>\n    <tr>\n      <th>98669</th>\n      <td>5</td>\n      <td>350.00</td>\n      <td>36.53</td>\n      <td>386.53</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>boleto</td>\n      <td>computers_accessories</td>\n      <td>8950</td>\n      <td>...</td>\n      <td>-9</td>\n      <td>7</td>\n      <td>-3</td>\n      <td>-23.535864</td>\n      <td>-46.642819</td>\n      <td>-25.566904</td>\n      <td>-49.309115</td>\n      <td>2.031041</td>\n      <td>2.666296</td>\n      <td>3.351755</td>\n    </tr>\n    <tr>\n      <th>98670</th>\n      <td>5</td>\n      <td>99.90</td>\n      <td>16.95</td>\n      <td>116.85</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>sports_leisure</td>\n      <td>967</td>\n      <td>...</td>\n      <td>-13</td>\n      <td>10</td>\n      <td>-5</td>\n      <td>-25.469955</td>\n      <td>-49.289821</td>\n      <td>-23.597794</td>\n      <td>-46.643923</td>\n      <td>-1.872161</td>\n      <td>-2.645898</td>\n      <td>3.241260</td>\n    </tr>\n    <tr>\n      <th>98671</th>\n      <td>5</td>\n      <td>55.99</td>\n      <td>8.72</td>\n      <td>64.71</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>computers_accessories</td>\n      <td>100</td>\n      <td>...</td>\n      <td>-9</td>\n      <td>8</td>\n      <td>-6</td>\n      <td>-23.635530</td>\n      <td>-46.694031</td>\n      <td>-23.040252</td>\n      <td>-46.979782</td>\n      <td>-0.595278</td>\n      <td>0.285751</td>\n      <td>0.660310</td>\n    </tr>\n    <tr>\n      <th>98672</th>\n      <td>5</td>\n      <td>43.00</td>\n      <td>12.79</td>\n      <td>55.79</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>credit_card</td>\n      <td>bed_bath_table</td>\n      <td>600</td>\n      <td>...</td>\n      <td>-14</td>\n      <td>6</td>\n      <td>-2</td>\n      <td>-21.757321</td>\n      <td>-48.829744</td>\n      <td>-22.916957</td>\n      <td>-48.441709</td>\n      <td>1.159637</td>\n      <td>-0.388034</td>\n      <td>1.222836</td>\n    </tr>\n  </tbody>\n</table>\n<p>98673 rows × 23 columns</p>\n</div>",
            "text/plain": "       review_score  item_price_mean  freight_value_mean  total_payment  \\\n0                 5            58.90               13.29          72.19   \n1                 4           239.90               19.93         259.83   \n2                 5           199.00               17.87         216.87   \n3                 4            12.99               12.79          25.78   \n4                 5           199.90               18.14         218.04   \n...             ...              ...                 ...            ...   \n98668             5           299.99               43.41         343.40   \n98669             5           350.00               36.53         386.53   \n98670             5            99.90               16.95         116.85   \n98671             5            55.99                8.72          64.71   \n98672             5            43.00               12.79          55.79   \n\n       n_items  unique_items  unique_sellers payment_type  \\\n0            1             1               1  credit_card   \n1            1             1               1  credit_card   \n2            1             1               1  credit_card   \n3            1             1               1  credit_card   \n4            1             1               1  credit_card   \n...        ...           ...             ...          ...   \n98668        1             1               1       boleto   \n98669        1             1               1       boleto   \n98670        1             1               1  credit_card   \n98671        1             1               1  credit_card   \n98672        1             1               1  credit_card   \n\n            product_category  product_weight_g_sum  ...  delivery_delay_days  \\\n0                 cool_stuff                   650  ...                   -9   \n1                   pet_shop                 30000  ...                   -3   \n2            furniture_decor                  3050  ...                  -14   \n3                  perfumery                   200  ...                   -6   \n4               garden_tools                  3750  ...                  -16   \n...                      ...                   ...  ...                  ...   \n98668             housewares                 10150  ...                   -8   \n98669  computers_accessories                  8950  ...                   -9   \n98670         sports_leisure                   967  ...                  -13   \n98671  computers_accessories                   100  ...                   -9   \n98672         bed_bath_table                   600  ...                  -14   \n\n       purchase_month  shipping_delay_days  seller_lat  seller_lng  \\\n0                   9                    0  -22.496953  -44.127492   \n1                   4                    1  -23.565096  -46.518565   \n2                   1                   -3  -22.262584  -46.171124   \n3                   8                   -5  -20.553624  -47.387359   \n4                   2                    2  -22.929384  -53.135873   \n...               ...                  ...         ...         ...   \n98668               4                   -7  -26.912574  -48.673980   \n98669               7                   -3  -23.535864  -46.642819   \n98670              10                   -5  -25.469955  -49.289821   \n98671               8                   -6  -23.635530  -46.694031   \n98672               6                   -2  -21.757321  -48.829744   \n\n       customer_lat  customer_lng   lat_diff  lng_diff   geo_diff  \n0        -21.762775    -41.309633  -0.734177 -2.817859   2.911932  \n1        -20.220527    -50.903424  -3.344569  4.384859   5.514810  \n2        -19.870305    -44.593326  -2.392279 -1.577798   2.865737  \n3        -23.089925    -46.611654   2.536302 -0.775705   2.652271  \n4        -23.243402    -46.827614   0.314018 -6.308258   6.316069  \n...             ...           ...        ...       ...        ...  \n98668     -2.497993    -44.297761 -24.414581 -4.376219  24.803690  \n98669    -25.566904    -49.309115   2.031041  2.666296   3.351755  \n98670    -23.597794    -46.643923  -1.872161 -2.645898   3.241260  \n98671    -23.040252    -46.979782  -0.595278  0.285751   0.660310  \n98672    -22.916957    -48.441709   1.159637 -0.388034   1.222836  \n\n[98673 rows x 23 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1761503356031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "envs = ml_client.environments.list()\n",
        "for env in envs:\n",
        "    print(env.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sentiment-analysis-env3\nsentiment-analysis-env2\nsentiment_analysis_env\nAzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1760219206890
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_env = Environment(\n",
        "    name=\"sentiment-analysis-env3\",\n",
        "    description=\"Environment for sentiment analysis deployment\",\n",
        "    conda_file=\"./zunkuaz/src/sentiment-analysis-env.yml\",\n",
        "    image=\"mcr.microsoft.com/azureml/curated/minimal-py311-inference:36\",\n",
        "    version='15'\n",
        ")\n",
        "#ml_client.environments.create_or_update(my_env)"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1761851559432
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = ml_client.environments.get(name='sentiment-analysis-env3', version=\"14\")\n",
        "print(env)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "conda_file:\n  channels:\n  - defaults\n  dependencies:\n  - python=3.11\n  - pip\n  - pip:\n    - scikit-learn\n    - pandas\n    - numpy\n    - nltk\n    - joblib\n    - azureml-mlflow\n    - matplotlib\n  name: sentiment-analysis-env3\ncreation_context:\n  created_at: '2025-10-24T22:49:12.192621+00:00'\n  created_by: Daniel Mendez\n  created_by_type: User\n  last_modified_at: '2025-10-24T22:49:12.192621+00:00'\n  last_modified_by: Daniel Mendez\n  last_modified_by_type: User\ndescription: Environment for sentiment analysis deployment\nid: azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/environments/sentiment-analysis-env3/versions/14\nimage: mcr.microsoft.com/azureml/curated/minimal-py311-inference:36\nname: sentiment-analysis-env3\nos_type: linux\ntags: {}\nversion: '14'\n\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1761346163089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crenado un MLflow experiment, te permite agrupar tus ejecuciones.\n",
        "mlflow.set_experiment(experiment_name=\"sentiment_analysis\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025/10/09 23:29:38 INFO mlflow.tracking.fluent: Experiment with name 'sentiment_analysis' does not exist. Creating a new experiment.\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "<Experiment: artifact_location='', creation_time=1760052578867, experiment_id='5d0ada56-50ca-460a-8988-9687bb3ea741', last_update_time=None, lifecycle_stage='active', name='sentiment_analysis', tags={}>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1760052578628
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model = LogisticRegression(C=10, penalty='l1',class_weight='balanced',random_state=42,solver='liblinear')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "    mlflow.log_metric('accuracy',accuracy)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n  warnings.warn(\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1760122181911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "\n",
        "sentiment_classifier_job = command(\n",
        "    code='./zunkuaz',\n",
        "    command='python src/prep-data.py --input_data ${{inputs.training_data}} --output_folder ${{outputs.clean_data}}',\n",
        "    inputs={\n",
        "        'training_data': Input(type='uri_file', path='azureml://subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourcegroups/brazilian-ecommerce-sentiment-analysis/workspaces/sentiment-analysis/datastores/workspaceblobstore/paths/UI/2025-10-09_220232_UTC/olist_order_reviews_dataset.csv')\n",
        "    },\n",
        "    outputs={\n",
        "        'clean_data': Output(type=AssetTypes.URI_FOLDER),\n",
        "    },\n",
        "    environment='sentiment-analysis-env3:11',\n",
        "    compute='zunku-comp-instance',\n",
        "    experiment_name='sentiment_analysis'\n",
        ")\n",
        "\n",
        "returned_job = ml_client.create_or_update(sentiment_classifier_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading zunkuaz (0.11 MBs): 100%|██████████| 108103/108103 [00:00<00:00, 2289024.53it/s]\n\u001b[39m\n\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1760564946577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = './zunkuaz/src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "./zunkuaz/src folder created\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1761842572822
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/prep-data.py\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from scipy.sparse import save_npz\n",
        "\n",
        "import sys\n",
        "sys.path.append(str(Path(__file__).resolve().parents[1]))\n",
        "from utilities.custom_transformers import import_data, DropNullData, DropDuplicates\n",
        "from utilities.text_utils import re_breakline, re_dates, re_hiperlinks, re_money, re_negation, re_numbers, \\\n",
        "    re_special_chars, re_whitespaces, ApplyRegex, StemmingProcess, StopWordsRemoval\n",
        "from utilities.text_prep import text_transformers\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\"\"\"\n",
        "-----------------------------------\n",
        "------ 0. PROJECT VARIABLES -------\n",
        "-----------------------------------\n",
        "\"\"\"\n",
        "\n",
        "# Variables for reading the data\n",
        "FILENAME = 'olist_order_reviews_dataset.csv'\n",
        "COLS_READ = ['review_comment_message', 'review_score']\n",
        "CORPUS_COL = 'review_comment_message'\n",
        "TARGET_COL = 'target'\n",
        "\n",
        "# Defining stopwords\n",
        "PT_STOPWORDS = stopwords.words('portuguese')\n",
        "\n",
        "\"\"\"\n",
        "This python script will allocate all the custom transformers that are specific for the project task.\n",
        "The idea is to encapsulate the classes and functions used on pipelines to make codes cleaner.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "-----------------------------------\n",
        "----- 1. CUSTOM TRANSFORMERS ------\n",
        "           1.1 Classes\n",
        "-----------------------------------\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class ColumnMapping(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    This class applies the map() function into a DataFrame for transforming a columns given a mapping dictionary\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    :param old_col_name: name of the columns where mapping will be applied [type: string]\n",
        "    :param mapping_dict: python dictionary with key/value mapping [type: dict]\n",
        "    :param new_col_name: name of the new column resulted by mapping [type: string, default: 'target]\n",
        "    :param drop: flag that guides the dropping of the old_target_name column [type: bool, default: True]\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    :return X: pandas DataFrame object after mapping application [type: pd.DataFrame]\n",
        "\n",
        "    Application\n",
        "    -----------\n",
        "    # Transforming a DataFrame column given a mapping dictionary\n",
        "    mapper = ColumnMapping(old_col_name='col_1', mapping_dict=dictionary, new_col_name='col_2', drop=True)\n",
        "    df_mapped = mapper.fit_transform(df)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, old_col_name, mapping_dict, new_col_name='target', drop=True):\n",
        "        self.old_col_name = old_col_name\n",
        "        self.mapping_dict = mapping_dict\n",
        "        self.new_col_name = new_col_name\n",
        "        self.drop = drop\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        # Applying mapping\n",
        "        X[self.new_col_name] = X[self.old_col_name].map(self.mapping_dict)\n",
        "\n",
        "        # Dropping the old columns (if applicable)\n",
        "        if self.drop:\n",
        "            X.drop(self.old_col_name, axis=1, inplace=True)\n",
        "\n",
        "        return X\n",
        "\n",
        "def main(args):\n",
        "    # Read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    X, X_prep, y = clean_data(df)\n",
        "\n",
        "    # Crea la carpeta si no existe\n",
        "    output_folder = args.output_folder\n",
        "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "    save_npz(Path(output_folder) / 'vectorized_comments.npz', X_prep)\n",
        "    # X_prep.tocsc((Path(output_folder) / 'vectorized_comments.csc'))\n",
        "    y.to_csv(Path(output_folder) / 'target.csv')\n",
        "    X.to_csv(Path(output_folder) / 'comments.csv')\n",
        "\n",
        "# Function that reads data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    row_count = (len(df))\n",
        "    print(f'Preparing {row_count} rows of data'.format(row_count))\n",
        "    return df\n",
        "\n",
        "# Funtion that removes missing values, drop duplicates, apply text transformers, and maps the target (review_score) to positive/negative reviews\n",
        "def clean_data(df):\n",
        "    # Creating a dictionary for mapping the target column based on review score\n",
        "    score_map = {\n",
        "        1: 0,\n",
        "        2: 0,\n",
        "        3: 0,\n",
        "        4: 1,\n",
        "        5: 1\n",
        "    }\n",
        "\n",
        "    # Selecting columns\n",
        "    df_prep = df[COLS_READ]\n",
        "    # Creating a pipeline for the initial prep on the data\n",
        "    initial_prep_pipeline = Pipeline([\n",
        "        ('mapper', ColumnMapping(old_col_name='review_score', mapping_dict=score_map, new_col_name=TARGET_COL)),\n",
        "        ('null_dropper', DropNullData()),\n",
        "        ('dup_dropper', DropDuplicates())\n",
        "    ])\n",
        "    # Applying initial prep pipeline\n",
        "    df_prep = initial_prep_pipeline.fit_transform(df_prep)\n",
        "\n",
        "    # Applying text transformations\n",
        "    X = df_prep[CORPUS_COL]\n",
        "    text_list = df_prep[CORPUS_COL].to_list()\n",
        "    text_pipeline = text_transformers()\n",
        "    X_prep = text_pipeline.fit_transform(text_list)\n",
        "    y = df_prep[TARGET_COL]\n",
        "    print(X)\n",
        "    return X, X_prep, y\n",
        "\n",
        "    # Setup arg parser\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # Add arguments\n",
        "    parser.add_argument('--input_data', dest='input_data', type=str)\n",
        "    parser.add_argument('--output_folder', dest='output_folder', type=str)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "# Run script\n",
        "if __name__ == '__main__':\n",
        "    # Add space in logs\n",
        "    print('\\n\\n')\n",
        "    print('*' * 60)\n",
        "\n",
        "    # Parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # Run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./zunkuaz/src/prep-data.py\n"
        }
      ],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1760289347148
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "from azure.ai.ml.entities import Component\n",
        "\n",
        "\n",
        "parent_dir = './zunkuaz'\n",
        "prep_data = load_component(source= parent_dir + '/src/prep-data.yaml')\n",
        "\n",
        "ml_client.components.create_or_update(prep_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading zunkuaz (0.09 MBs): 100%|██████████| 92824/92824 [00:00<00:00, 1787985.59it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 76,
          "data": {
            "text/plain": "CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'prep_data', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/components/prep_data/versions/2.8', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/zunku-comp-instance/code/Users', 'creation_context': <azure.ai.ml._restclient.v2024_01_01_preview.models._models_py3.SystemData object at 0x745b2315e590>, 'serialize': <msrest.serialization.Serializer object at 0x745b25865240>, 'command': 'python src/prep-data.py --input_data ${{inputs.input_data}} --output_folder ${{outputs.output_data}}', 'code': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/codes/70e35d8c-ef8f-453b-8790-b6af48309c30/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/environments/sentiment-analysis-env3/versions/15', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2.8', 'schema': 'https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json', 'type': 'command', 'display_name': 'Prepare training data', 'is_deterministic': True, 'inputs': {'input_data': {'type': 'uri_file', 'optional': False}}, 'outputs': {'output_data': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': []})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1761515876080
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train-model.py\n",
        "\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.sparse import load_npz\n",
        "import os\n",
        "#from mlflow.models.signature import infer_signature\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append(str(Path(__file__).resolve().parents[1]))\n",
        "\n",
        "def main(args):\n",
        "    with mlflow.start_run():\n",
        "        # read data\n",
        "        X_prep, y = get_data_from_folder(args.training_data)\n",
        "\n",
        "        # split data\n",
        "        X_train, X_test, y_train, y_test = split_data(X_prep, y)\n",
        "\n",
        "        # train model\n",
        "        class_weight = None if args.class_weight == 'Nini' else args.class_weight\n",
        "        model = train_model(class_weight, args.penalty, args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "        ########## NUEVOOO\n",
        "        # create the signature by inferring it from the datasets\n",
        "        #signature = infer_signature(X_prep, y)\n",
        "\n",
        "        # manually log the model\n",
        "        #mlflow.sklearn.log_model(model, artifact_path='model_output', signature=signature)\n",
        "\n",
        "        # evaluate model\n",
        "        eval_model(model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data_from_folder(folder_path):\n",
        "    print(\"Reading data...\")\n",
        "\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if file_name.startswith('comments'):\n",
        "            X = pd.read_csv(file_path)\n",
        "        elif file_name.startswith('target'):\n",
        "            y = pd.read_csv(file_path)\n",
        "        elif file_name.endswith('.npz'):\n",
        "            X_prep = load_npz(file_path)\n",
        "\n",
        "    return X_prep, y\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(X_prep, y):\n",
        "    print(\"Splitting data...\")\n",
        "    y = pd.Series(y['target'].values)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_prep, y, test_size=0.20, random_state=0)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(class_weight, penalty, reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    mlflow.log_param('Class Weight', class_weight)\n",
        "    mlflow.log_param('Penalty', penalty)\n",
        "    print(\"Training model...\")\n",
        "    \n",
        "    # Training model\n",
        "    model = LogisticRegression(C=reg_rate, solver=\"liblinear\", penalty=penalty, class_weight=class_weight).fit(X_train, y_train)\n",
        "\n",
        "    # Log with MLFlow to compare metrics and easy registry\n",
        "    mlflow.sklearn.log_model(model, artifact_path='model_output')\n",
        "\n",
        "    # Localy save model to pass as an output to the next component in the pipeline\n",
        "    mlflow.sklearn.save_model(model, path=args.model_output)\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test, X_train, y_train):\n",
        "    print('Evaluating model...')\n",
        "    # Calculate performance\n",
        "    # performance = trainer.evaluate_performance(X_train, y_train, X_test, y_test, cv=5, save=False)\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = np.average(y_pred == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # Calculate F1 Score\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    mlflow.log_metric('f1_score', f1)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float)\n",
        "    parser.add_argument('--class_weight', dest='class_weight',\n",
        "                        type=str)\n",
        "    parser.add_argument('--penalty', dest='penalty',\n",
        "                        type=str)\n",
        "    parser.add_argument('--model_output', dest='model_output', \n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./zunkuaz/src/train-model.py\n"
        }
      ],
      "execution_count": 66,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "from azure.ai.ml.entities import Component\n",
        "\n",
        "parent_dir = './zunkuaz'\n",
        "t_model = load_component(source= parent_dir + '/src/train-model.yaml')\n",
        "\n",
        "ml_client.components.create_or_update(t_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading zunkuaz (0.09 MBs):   0%|          | 0/92597 [00:00<?, ?it/s]\r\u001b[32mUploading zunkuaz (0.09 MBs): 100%|██████████| 92597/92597 [00:00<00:00, 1655272.80it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'train_model', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/components/train_model/versions/6.5', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/zunku-comp-instance/code/Users', 'creation_context': <azure.ai.ml._restclient.v2024_01_01_preview.models._models_py3.SystemData object at 0x745b258ac220>, 'serialize': <msrest.serialization.Serializer object at 0x745b23244fd0>, 'command': 'python src/train-model.py --training_data ${{inputs.training_data}} --reg_rate ${{inputs.reg_rate}} --penalty ${{inputs.penalty}} --class_weight ${{inputs.class_weight}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/codes/90a6defe-80b5-4961-9ef9-123506f0f3b8/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/environments/sentiment-analysis-env3/versions/14', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '6.5', 'schema': 'https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json', 'type': 'command', 'display_name': 'Train a logistic regression language model', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'uri_folder', 'optional': False}, 'reg_rate': {'type': 'number', 'default': 0.01, 'optional': False}, 'penalty': {'type': 'string', 'default': 'l1', 'optional': False}, 'class_weight': {'type': 'string', 'default': 'balanced', 'optional': False}}, 'outputs': {'model_output': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': []})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1761513835254
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = ml_client.jobs.list(parent_job_name='b3ac8b41-26ef-4208-887e-7bc3dc36f992')\n",
        "for run in runs:\n",
        "    print(run.properties)\n",
        "    #help(run)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'primary_metric_config': '{\"name\":\"f1_score\",\"goal\":\"maximize\"}', 'resume_from': 'null', 'runTemplate': 'HyperDrive', 'azureml.runsource': 'hyperdrive', 'platform': 'AML', 'ContentSnapshotId': 'd316710e-ea18-4bf3-8e41-69c47aa8db66', 'user_agent': 'Pipelines-hyperdrivecloud/1.0.0+565d08dd54e12f8f39523a22aa33bbe734f7e6af (20250929.1 565d08dd54e12f8f39523a22aa33bbe734f7e6af eastus)', 'azureml.moduleid': '22b3ab32-9700-441d-b712-dc0f8e64bb49', 'azureml.moduleFamilyId': 'a3aeb22c-df85-4251-9ec2-551157a03d06', 'best_child_run_id': 'HD_85ac40db-0656-4e08-b309-d37d020bb67a_0', 'score': '0.9073002448252838', 'best_metric_status': 'Succeeded', 'best_data_container_id': 'dcid.HD_85ac40db-0656-4e08-b309-d37d020bb67a_0'}\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1761506893575
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = ml_client.jobs.get('b3ac8b41-26ef-4208-887e-7bc3dc36f992')"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_BaseJob' object has no attribute 'outputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m job \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb3ac8b41-26ef-4208-887e-7bc3dc36f992\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_BaseJob' object has no attribute 'outputs'"
          ]
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1761507058185
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Registry model with an output job\n",
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "model = Model(\n",
        "    path='azureml://subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourcegroups/brazilian-ecommerce-sentiment-analysis/workspaces/sentiment-analysis/datastores/workspaceblobstore/paths/azureml/hungry_goat_zl4g7kf069_0/model_output/',\n",
        "    type='mlflow_model',\n",
        "    name='logreg-best'\n",
        ")\n",
        "\n",
        "registered_model = ml_client.models.create_or_update(model)"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1760999231779
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Registry model with a job.get\n",
        "job = ml_client.jobs.get('b3ac8b41-26ef-4208-887e-7bc3dc36f992')\n",
        "job_name = job.name\n",
        "run_model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
        "    name=\"mlflow-diabetes\",\n",
        "    description=\"Model created from run.\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        ")\n",
        "# Uncomment after adding required details above\n",
        "ml_client.models.create_or_update(run_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/sentiment-classifier.py\n",
        "\n",
        "# import libraries\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.sparse import load_npz\n",
        "import os\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from mlflow.models.signature import infer_signature\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append(str(Path(__file__).resolve().parents[1]))\n",
        "\n",
        "from utilities.ml_utils import BinaryClassifiersAnalysis, cross_val_performance\n",
        "from utilities.text_prep import text_transformers\n",
        "\n",
        "def main(args):\n",
        "    with mlflow.start_run():\n",
        "        # read data\n",
        "        X, X_prep, y, model = get_data_and_model(args.training_data, args.model_input)\n",
        "\n",
        "        # train sentiment classifier\n",
        "        sentiment_classifier = train_sentiment_classifier(X, X_prep, y, model)\n",
        "\n",
        "\n",
        "def get_data_and_model(folder_path, model_path):\n",
        "    print(\"Reading data...\")\n",
        "\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if file_name.startswith('comments'):\n",
        "            X = pd.read_csv(file_path)\n",
        "        elif file_name.startswith('target'):\n",
        "            y = pd.read_csv(file_path)\n",
        "        elif file_name.endswith('.npz'):\n",
        "            X_prep = load_npz(file_path)\n",
        "\n",
        "    model = mlflow.sklearn.load_model(model_path)\n",
        "    print(f'Loaded model from: {model_path}')\n",
        "\n",
        "    return X, X_prep, y, model\n",
        "\n",
        "def train_sentiment_classifier(X, X_prep, y, model):\n",
        "\n",
        "    # Creating a complete pipeline for prep and predict\n",
        "    text_pipeline = text_transformers()\n",
        "    e2e_pipeline = Pipeline([\n",
        "        ('text_prep', text_pipeline),\n",
        "        ('model', model)\n",
        "        ])\n",
        "    print('Created pipeline')\n",
        "\n",
        "    # Defining a param grid for searching best pipelines options\n",
        "    \"\"\"\n",
        "    param_grid = [{\n",
        "        'text_prep__vectorizer__max_features': np.arange(500, 851, 50),\n",
        "        'text_prep__vectorizer__min_df': [7, 9, 12, 15, 30],\n",
        "        'text_prep__vectorizer__max_df': [.4, .5, .6, .7]\n",
        "    }]\n",
        "    \"\"\"\n",
        "\n",
        "    param_grid = [{\n",
        "    'text_prep__vectorizer__max_features': np.arange(500, 501, 50),\n",
        "    'text_prep__vectorizer__min_df': [7],\n",
        "    'text_prep__vectorizer__max_df': [.4]\n",
        "    }]\n",
        "\n",
        "    # Searching for the best options\n",
        "    grid_search_prep = GridSearchCV(e2e_pipeline, param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
        "    text_list = X['review_comment_message'].to_list()\n",
        "    y = pd.Series(y['target'].values)\n",
        "    grid_search_prep.fit(text_list,y)\n",
        "    print('Best params after a complete search: ')\n",
        "    print(grid_search_prep.best_params_)\n",
        "\n",
        "    # Returning the best options\n",
        "    vectorizer_max_features = grid_search_prep.best_params_['text_prep__vectorizer__max_features']\n",
        "    vectorizer_min_df = grid_search_prep.best_params_['text_prep__vectorizer__min_df']\n",
        "    vectorizer_max_df = grid_search_prep.best_params_['text_prep__vectorizer__max_df']\n",
        "\n",
        "    # Updating the e2e pipeline with the best options found on search\n",
        "    e2e_pipeline.named_steps['text_prep'].named_steps['vectorizer'].max_features = vectorizer_max_features\n",
        "    e2e_pipeline.named_steps['text_prep'].named_steps['vectorizer'].min_df = vectorizer_min_df\n",
        "    e2e_pipeline.named_steps['text_prep'].named_steps['vectorizer'].max_df = vectorizer_max_df\n",
        "\n",
        "    # Fitting the model again\n",
        "    e2e_pipeline.fit(text_list, y)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "    # Retrieving performance for te final model after hyperparam updating\n",
        "    final_model = e2e_pipeline.named_steps['model']\n",
        "    final_performance = cross_val_performance(final_model, X_prep, y, cv=5)\n",
        "    print(final_performance)\n",
        "    # Log with MLFlow to easy registry\n",
        "    signature = infer_signature(text_list, e2e_pipeline.predict(text_list))\n",
        "    mlflow.sklearn.log_model(final_model, artifact_path='model_output', signature=signature)\n",
        "    mlflow.sklearn.save_model(final_model, path=args.model_output, signature=signature)\n",
        "    return final_model\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument('--model_input', dest='model_input', \n",
        "                        type=str)\n",
        "    parser.add_argument('--model_output', dest='model_output',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./zunkuaz/src/sentiment-classifier.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "from azure.ai.ml.entities import Component\n",
        "\n",
        "parent_dir = './zunkuaz'\n",
        "s_classifier = load_component(source= parent_dir + '/src/sentiment-classifier.yaml')\n",
        "\n",
        "ml_client.components.create_or_update(s_classifier)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading zunkuaz (0.1 MBs): 100%|██████████| 96530/96530 [00:00<00:00, 1559327.11it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "CommandComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'sentiment_classifier', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/components/sentiment_classifier/versions/2.4', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/zunku-comp-instance/code/Users', 'creation_context': <azure.ai.ml._restclient.v2024_01_01_preview.models._models_py3.SystemData object at 0x7befcc71bdf0>, 'serialize': <msrest.serialization.Serializer object at 0x7befcc71b610>, 'command': 'python src/sentiment-classifier.py --training_data ${{inputs.training_data}} --model_input ${{inputs.model_input}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/codes/82e8c26c-9fdb-4080-9cbd-044c4d591530/versions/1', 'environment_variables': None, 'environment': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/environments/sentiment-analysis-env3/versions/14', 'distribution': None, 'resources': {'instance_count': 1}, 'queue_settings': None, 'version': '2.4', 'schema': 'https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json', 'type': 'command', 'display_name': 'Train the final sentiment classifier model', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'uri_folder', 'optional': False}, 'model_input': {'type': 'uri_folder', 'optional': False}}, 'outputs': {'model_output': {'type': 'uri_folder'}}, 'yaml_str': None, 'other_parameter': {}, 'additional_includes': []})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1761860082137
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.sweep import SweepJob, Objective, Choice, QUniform\n",
        "from azure.ai.ml.sweep import MedianStoppingPolicy\n",
        "# Sweep basado en el componente sin crear, solo referencia, es la manera ideal para hacer pruebas con el\n",
        "\n",
        "# Si lo ejecuto desde el notebook, la ruta donde se ejecuta es la del mismo notebook\n",
        "command_component_job_for_sweep = t_model(\n",
        "    training_data = Input(type=\"uri_folder\", path=\"azureml:cleaned_data:1\"),\n",
        "    reg_rate = QUniform(1e-5,150,.001),\n",
        "    penalty = Choice(values=['l1','l2']),\n",
        "    class_weight = Choice(values=[\"balanced\",'None'])\n",
        ")\n",
        "\n",
        "cmd_component_sweep_job = command_component_job_for_sweep.sweep(\n",
        "    compute='zunku-comp-instance',\n",
        "    sampling_algorithm='random',\n",
        "    primary_metric='F1 Score',\n",
        "    goal='maximize'\n",
        ")\n",
        "\n",
        "\n",
        "# Podemos acceder a las propiedades del componente, como su descripcion, nombre, todo\n",
        "cmd_component_sweep_job.description = 'Second step of a pipeline, a sweep job that use the cleaned data to train a logistic regression model, trying several hyperparameters'\n",
        "\n",
        "cmd_component_sweep_job.set_limits(\n",
        "    max_total_trials=2, timeout=7200\n",
        ")\n",
        "\n",
        "# Early termination policy, end sweep job if the model stop improving\n",
        "cmd_component_sweep_job.early_termination = MedianStoppingPolicy(\n",
        "    evaluation_interval=1, \n",
        "    delay_evaluation=3 \n",
        ")\n",
        "\n",
        "returned_job = ml_client.jobs.create_or_update(cmd_component_sweep_job)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 't_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msweep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MedianStoppingPolicy\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Sweep basado en el componente sin crear, solo referencia, es la manera ideal para hacer pruebas con el\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Si lo ejecuto desde el notebook, la ruta donde se ejecuta es la del mismo notebook\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m command_component_job_for_sweep \u001b[38;5;241m=\u001b[39m \u001b[43mt_model\u001b[49m(\n\u001b[1;32m      7\u001b[0m     training_data \u001b[38;5;241m=\u001b[39m Input(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazureml:cleaned_data:1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     reg_rate \u001b[38;5;241m=\u001b[39m QUniform(\u001b[38;5;241m1e-5\u001b[39m,\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m.001\u001b[39m),\n\u001b[1;32m      9\u001b[0m     penalty \u001b[38;5;241m=\u001b[39m Choice(values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     10\u001b[0m     class_weight \u001b[38;5;241m=\u001b[39m Choice(values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m cmd_component_sweep_job \u001b[38;5;241m=\u001b[39m command_component_job_for_sweep\u001b[38;5;241m.\u001b[39msweep(\n\u001b[1;32m     14\u001b[0m     compute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzunku-comp-instance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     sampling_algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m     primary_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 Score\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     goal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Podemos acceder a las propiedades del componente, como su descripcion, nombre, todo\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 't_model' is not defined"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1761000041183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo QUniform\n",
        "min_value, max_value, q = .5,100,1\n",
        "values = np.arange(min_value, max_value, q)\n",
        "print(values)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[ 0.5  1.5  2.5  3.5  4.5  5.5  6.5  7.5  8.5  9.5 10.5 11.5 12.5 13.5\n 14.5 15.5 16.5 17.5 18.5 19.5 20.5 21.5 22.5 23.5 24.5 25.5 26.5 27.5\n 28.5 29.5 30.5 31.5 32.5 33.5 34.5 35.5 36.5 37.5 38.5 39.5 40.5 41.5\n 42.5 43.5 44.5 45.5 46.5 47.5 48.5 49.5 50.5 51.5 52.5 53.5 54.5 55.5\n 56.5 57.5 58.5 59.5 60.5 61.5 62.5 63.5 64.5 65.5 66.5 67.5 68.5 69.5\n 70.5 71.5 72.5 73.5 74.5 75.5 76.5 77.5 78.5 79.5 80.5 81.5 82.5 83.5\n 84.5 85.5 86.5 87.5 88.5 89.5 90.5 91.5 92.5 93.5 94.5 95.5 96.5 97.5\n 98.5 99.5]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1760906043484
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# QLogUniform Example\n",
        "min_value, max_value, q = 1e-5,150,.001\n",
        "def qloguniform(min_val, max_val, q, num_samples=50):\n",
        "    # Paso 1: valores logarítmicos uniformes\n",
        "    log_min, log_max = np.log(min_val), np.log(max_val)\n",
        "    log_samples = np.random.uniform(log_min, log_max, num_samples)\n",
        "    \n",
        "    # Paso 2: volver al espacio original\n",
        "    samples = np.exp(log_samples)\n",
        "    \n",
        "    # Paso 3: aplicar cuantización\n",
        "    quantized = np.round(samples / q) * q\n",
        "    return quantized\n",
        "\n",
        "values = qloguniform(min_value, max_value, q)\n",
        "print(values)\n",
        "plt.hist(values, bins=20)\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[0.00000e+00 9.14500e+00 4.03000e-01 1.56700e+00 3.81380e+01 3.13110e+01\n 7.79000e-01 1.03900e+00 0.00000e+00 5.55000e-01 1.45249e+02 0.00000e+00\n 0.00000e+00 2.28100e+00 1.00000e-03 1.10000e-02 2.25340e+01 0.00000e+00\n 9.50800e+01 3.51700e+00]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": "<Figure size 640x480 with 1 Axes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 71,
      "metadata": {
        "gather": {
          "logged": 1760823414874
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./zunkuaz/utilities/text_prep.py\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "from utilities.text_utils import re_breakline, re_dates, re_hiperlinks, re_money, re_negation, re_numbers, \\\n",
        "    re_special_chars, re_whitespaces, ApplyRegex, StemmingProcess, StopWordsRemoval\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Function that apply Regular Expressions, stopwords and other techniques to comments reviews\n",
        "def text_transformers():\n",
        "    # Defining regex transformers to be applied\n",
        "    regex_transformers = {\n",
        "        'break_line': re_breakline,\n",
        "        'hiperlinks': re_hiperlinks,\n",
        "        'dates': re_dates,\n",
        "        'money': re_money,\n",
        "        'numbers': re_numbers,\n",
        "        'negation': re_negation,\n",
        "        'special_chars': re_special_chars,\n",
        "        'whitespaces': re_whitespaces\n",
        "    }\n",
        "\n",
        "    # Building a text prep pipeline\n",
        "    text_prep_pipeline = Pipeline([\n",
        "        ('regex', ApplyRegex(regex_transformers)),\n",
        "        ('stopwords', StopWordsRemoval(stopwords.words('portuguese'))),\n",
        "        ('stemming', StemmingProcess(RSLPStemmer())),\n",
        "        ('vectorizer', TfidfVectorizer(max_features=300, min_df=7, max_df=0.8, stop_words=stopwords.words('portuguese')))\n",
        "    ])\n",
        "\n",
        "    #X_prep = text_prep_pipeline.fit_transform(text_list)\n",
        "    return text_prep_pipeline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./zunkuaz/utilities/text_prep.py\n"
        }
      ],
      "execution_count": 37,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml.sweep import SweepJob, Objective, Choice, QUniform\n",
        "from azure.ai.ml.sweep import MedianStoppingPolicy\n",
        "\n",
        "# Creating e2e pipeline\n",
        "@pipeline()\n",
        "def sentiment_analysis(pipeline_job_input):\n",
        "\n",
        "    # Step 1: Cleaning data\n",
        "\n",
        "    prep_data_component = ml_client.components.get('prep_data', version='2.8')\n",
        "    clean_data = prep_data_component(input_data=pipeline_job_input)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "    # Step 2: Training and validating model with a sweep job\n",
        "\n",
        "    train_component = ml_client.components.get('train_model', version='6.5')\n",
        "\n",
        "    # Sweep job grid\n",
        "    sweep_job = train_component(\n",
        "        training_data=clean_data.outputs.output_data,\n",
        "        reg_rate = QUniform(1,150,1),\n",
        "        penalty = Choice(values=['l1','l2']),\n",
        "        class_weight = Choice(values=[\"balanced\",\"Nini\"])\n",
        "    )\n",
        "     \n",
        "    # Configuration sweep job\n",
        "    sweep_job = sweep_job.sweep(\n",
        "        primary_metric='f1_score',\n",
        "        sampling_algorithm='random',\n",
        "        goal='maximize',\n",
        "        compute='zunku-comp-instance'\n",
        "    )\n",
        "\n",
        "    sweep_job.set_limits(\n",
        "        max_total_trials=2, timeout=7200\n",
        "    )\n",
        "\n",
        "    sweep_job.early_termination = MedianStoppingPolicy(\n",
        "        evaluation_interval=1, \n",
        "        delay_evaluation=3 \n",
        "    )\n",
        "\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "\n",
        "    # Step 3: Training sentiment classifier \n",
        "\n",
        "    sentiment_classifier_component = ml_client.components.get('sentiment_classifier', version='2.4')\n",
        "    sentiment_classifier = sentiment_classifier_component(\n",
        "        training_data = clean_data.outputs.output_data,\n",
        "        model_input = sweep_job.outputs.model_output\n",
        "    )\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "    # Pipeline returns\n",
        "    return{\n",
        "        #'pipeline_job_transformed_data': clean_data.outputs.output_data,\n",
        "        #'pipeline_job_trained_model' : sweep_job.outputs.model_output\n",
        "        'pipeline_job_sentiment_classifier' : sentiment_classifier.outputs.model_output\n",
        "    }\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "\n",
        "\n",
        "# Runing pipeline\n",
        "pipeline_job = sentiment_analysis(Input(type=AssetTypes.URI_FILE, path='azureml:olist_order_reviews:1'))\n",
        "\n",
        "# Changing pipeline job parameters\n",
        "\n",
        "# Changing output mode\n",
        "pipeline_job.outputs.pipeline_job_sentiment_classifier.mode = 'rw_mount'\n",
        "\n",
        "pipeline_job.settings.default_compute = 'zunku-comp-instance'\n",
        "\n",
        "pipeline_job.settings.default_datastore = 'workspaceblobstore'\n",
        "print(pipeline_job)\n",
        "\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name='pipeline_job'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "display_name: sentiment_analysis\ntype: pipeline\ninputs:\n  pipeline_job_input:\n    type: uri_file\n    path: azureml:olist_order_reviews:1\noutputs:\n  pipeline_job_sentiment_classifier:\n    mode: rw_mount\n    type: uri_folder\njobs:\n  clean_data:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.inputs.pipeline_job_input}}\n    resources:\n      instance_count: 1\n    component:\n      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n      name: prep_data\n      version: '2.8'\n      display_name: Prepare training data\n      type: command\n      inputs:\n        input_data:\n          type: uri_file\n          optional: false\n      outputs:\n        output_data:\n          type: uri_folder\n      command: python src/prep-data.py --input_data ${{inputs.input_data}} --output_folder\n        ${{outputs.output_data}}\n      environment: azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/environments/sentiment-analysis-env3/versions/15\n      code: azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/codes/70e35d8c-ef8f-453b-8790-b6af48309c30/versions/1\n      resources:\n        instance_count: 1\n      creation_context:\n        created_at: '2025-10-26T21:57:55.790326+00:00'\n        created_by: Daniel Mendez\n        created_by_type: User\n        last_modified_at: '2025-10-26T21:57:55.910275+00:00'\n        last_modified_by: Daniel Mendez\n        last_modified_by_type: User\n      id: /subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/components/prep_data/versions/2.8\n      is_deterministic: true\n  sweep_job:\n    type: sweep\n    inputs:\n      training_data:\n        path: ${{parent.jobs.clean_data.outputs.output_data}}\n    limits:\n      max_total_trials: 2\n      timeout: 7200\n    compute: azureml:zunku-comp-instance\n    early_termination:\n      evaluation_interval: 1\n      delay_evaluation: 3\n      type: median_stopping\n    objective:\n      goal: maximize\n      primary_metric: f1_score\n    sampling_algorithm: random\n    search_space:\n      reg_rate:\n        type: quniform\n        min_value: 1\n        max_value: 150\n        q: 1\n      penalty:\n        values:\n        - l1\n        - l2\n        type: choice\n      class_weight:\n        values:\n        - balanced\n        - Nini\n        type: choice\n    trial:\n      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n      name: train_model\n      version: '6.5'\n      display_name: Train a logistic regression language model\n      type: command\n      inputs:\n        training_data:\n          type: uri_folder\n          optional: false\n        reg_rate:\n          type: number\n          optional: false\n          default: '0.01'\n        penalty:\n          type: string\n          optional: false\n          default: l1\n        class_weight:\n          type: string\n          optional: false\n          default: balanced\n      outputs:\n        model_output:\n          type: uri_folder\n      command: python src/train-model.py --training_data ${{inputs.training_data}}\n        --reg_rate ${{inputs.reg_rate}} --penalty ${{inputs.penalty}} --class_weight\n        ${{inputs.class_weight}} --model_output ${{outputs.model_output}}\n      environment: azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/environments/sentiment-analysis-env3/versions/14\n      code: azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/codes/90a6defe-80b5-4961-9ef9-123506f0f3b8/versions/1\n      resources:\n        instance_count: 1\n      creation_context:\n        created_at: '2025-10-26T21:23:54.912831+00:00'\n        created_by: Daniel Mendez\n        created_by_type: User\n        last_modified_at: '2025-10-26T21:23:55.052568+00:00'\n        last_modified_by: Daniel Mendez\n        last_modified_by_type: User\n      id: /subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/components/train_model/versions/6.5\n      is_deterministic: true\n  sentiment_classifier:\n    type: command\n    inputs:\n      training_data:\n        path: ${{parent.jobs.clean_data.outputs.output_data}}\n      model_input:\n        path: ${{parent.jobs.sweep_job.outputs.model_output}}\n    outputs:\n      model_output: ${{parent.outputs.pipeline_job_sentiment_classifier}}\n    resources:\n      instance_count: 1\n    component:\n      $schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n      name: sentiment_classifier\n      version: '2.4'\n      display_name: Train the final sentiment classifier model\n      type: command\n      inputs:\n        training_data:\n          type: uri_folder\n          optional: false\n        model_input:\n          type: uri_folder\n          optional: false\n      outputs:\n        model_output:\n          type: uri_folder\n      command: python src/sentiment-classifier.py --training_data ${{inputs.training_data}}\n        --model_input ${{inputs.model_input}} --model_output ${{outputs.model_output}}\n      environment: azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/environments/sentiment-analysis-env3/versions/14\n      code: azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/codes/82e8c26c-9fdb-4080-9cbd-044c4d591530/versions/1\n      resources:\n        instance_count: 1\n      creation_context:\n        created_at: '2025-10-30T21:34:42.036273+00:00'\n        created_by: Daniel Mendez\n        created_by_type: User\n        last_modified_at: '2025-10-30T21:34:42.163239+00:00'\n        last_modified_by: Daniel Mendez\n        last_modified_by_type: User\n      id: /subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/components/sentiment_classifier/versions/2.4\n      is_deterministic: true\nsettings:\n  default_datastore: azureml:workspaceblobstore\n  default_compute: azureml:zunku-comp-instance\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1761860097357
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener los hijos (steps individuales)\n",
        "childrens = list(ml_client.jobs.list(parent_job_name=pipeline_job.name))\n",
        "\n",
        "# Por ejemplo, el primer hijo\n",
        "for children in childrens:\n",
        "    print(children.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "bc30aff2-55eb-4b92-a24e-1ca3632e4539\nb6e9dabf-fc7e-4e5a-9b25-4ea020095ad0\n64164134-2f1c-42b5-b50d-ad027006e294\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1761524276482
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print available outputs\n",
        "print(pipeline_job.outputs)\n",
        "\n",
        "# Getting pipeline job name\n",
        "pipeline_job = ml_client.jobs.get(pipeline_job.name)\n",
        "\n",
        "output_port_name = pipeline_job.outputs['pipeline_job_sentiment_classifier'].port_name\n",
        "# Download all the outputs of the job\n",
        "# output = ml_client.jobs.download(name=pipeline_job.name, download_path=tmp_path, all=True)\n",
        "\n",
        "# Download specific output\n",
        "tmp_path = './zunkuaz/tmp'\n",
        "output = ml_client.jobs.download(name=pipeline_job.name, download_path=tmp_path, output_name=output_port_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'pipeline_job_sentiment_classifier': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x7befcc283d30>}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Downloading artifact azureml://subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourcegroups/brazilian-ecommerce-sentiment-analysis/workspaces/sentiment-analysis/datastores/workspaceblobstore/paths/azureml/40c00e11-4b6b-4e9b-a361-9c28f9e8df02/model_output/ to zunkuaz/tmp/named-outputs/pipeline_job_sentiment_classifier\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1761860294120
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "\n",
        "model = Model(\n",
        "    path='./zunkuaz/tmp/named-outputs/pipeline_job_sentiment_classifier',\n",
        "    type='mlflow_model',\n",
        "    name='sentiment-classifier'\n",
        ")\n",
        "\n",
        "# registered_model = ml_client.models.create_or_update(model)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1761860403518
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and create and Online Endopoint\n",
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Online endpoint for MLflow sentiment classifier model\",\n",
        "    auth_mode=\"key\",\n",
        ")\n",
        "\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-10301809734550.eastus.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-10301809734550.eastus.inference.ml.azure.com/swagger.json', 'name': 'endpoint-10301809734550', 'description': 'Online endpoint for MLflow sentiment classifier model', 'tags': {}, 'properties': {'createdBy': 'Daniel Mendez', 'createdAt': '2025-10-30T18:09:51.775509+0000', 'lastModifiedAt': '2025-10-30T18:09:51.775509+0000', 'azureml.onlineendpointid': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourcegroups/brazilian-ecommerce-sentiment-analysis/providers/microsoft.machinelearningservices/workspaces/sentiment-analysis/onlineendpoints/endpoint-10301809734550', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oeidp:280e7043-048d-45b7-949c-f536b1ed03f3:bc2abbff-839c-4a45-bea8-0d4d568799aa?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/onlineEndpoints/endpoint-10301809734550', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/zunku-comp-instance/code/Users', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7722e06a9600>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7722e0735b70>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1761847884525
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# create a blue deployment\n",
        "online_endpoint_name = 'endpoint-10301809734550'\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_D2as_v4\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint endpoint-10301809734550 exists\n\u001b[32mUploading pipeline_job_sentiment_classifier (0.01 MBs): 100%|██████████| 5792/5792 [00:00<00:00, 104795.18it/s]\n\u001b[39m\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "......................................."
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1761860393896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment, CodeConfiguration\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# create a local online endpoint\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    environment=my_env,\n",
        "    code_configuration= CodeConfiguration(\n",
        "        code='./zunkuaz/src',\n",
        "        scoring_script='sentiment-classifier.py'\n",
        "    ),\n",
        "    instance_type=\"Standard_D2as_v4\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "ml_client.online_deployments.begin_create_or_update(blue_deployment, local=True, vscode_debug=True).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Creating local deployment (endpoint-10301809734550 / blue) .\nBuilding Docker image from Dockerfile\nStep 1/7 : FROM mcr.microsoft.com/azureml/curated/minimal-py311-inference:36\n ---> 559c34e765b2\nStep 2/7 : RUN mkdir -p /var/azureml-app/\n ---> Using cache\n ---> 03ff591c6f12\nStep 3/7 : WORKDIR /var/azureml-app/\n ---> Running in 3ae5505b261b\n ---> 110e6738246d\nStep 4/7 : COPY conda.yml /var/azureml-app/\n. ---> f7e99c99730a\nStep 5/7 : RUN conda env create -n inf-conda-env --file conda.yml\n ---> Running in 62f1f81f75f2\nRetrieving notices: done\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\npython-3.11.14       | 29.8 MB   |            |   0% \n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \u001b[A\u001b[A\n\n\u001b[A\u001b[A\n\n\n\u001b[A\u001b[A\u001b[A\n\n\n\n\nsetuptools-80.9.0    | 1.9 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nsqlite-3.50.2        | 1.1 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nxorg-libx11-1.8.12   | 895 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\nlibgomp-11.2.0       | 474 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nreadline-8.3         | 471 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbzip2-1.0.8          | 262 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpat-2.7.1          | 182 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\nlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \u001b[A\u001b[A\n\n\nopenssl-3.0.18       | 4.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\nlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \u001b[A\n\nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \u001b[A\u001b[A\n\n\npython-3.11.14       | 29.8 MB   |            |   0% \nlibgcc-ng-11.2.0     | 5.3 MB    | ########8  |  89% \u001b[A\n\n\n\n\npython-3.11.14       | 29.8 MB   | #1         |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ntk-8.6.15            | 3.4 MB    | #######9   |  80% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\u001b[A\u001b[A\n\n\nopenssl-3.0.18       | 4.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n\n\n\n\npython-3.11.14       | 29.8 MB   | ##3        |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \u001b[A\n\n\n\ntk-8.6.15            | 3.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npip-25.2             | 1.1 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npython-3.11.14       | 29.8 MB   | ###6       |  37% \n\n\n\n\n\n\n\nncurses-6.5          | 1.1 MB    | 1          |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nsqlite-3.50.2        | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nxorg-libx11-1.8.12   | 895 KB    | 1          |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nncurses-6.5          | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\npython-3.11.14       | 29.8 MB   | ####8      |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nxorg-xorgproto-2024. | 580 KB    | 2          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nxorg-libx11-1.8.12   | 895 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\nld_impl_linux-64-2.4 | 672 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\npython-3.11.14       | 29.8 MB   | #####9     |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\nxz-5.6.4             | 567 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nreadline-8.3         | 471 KB    | 3          |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibxcb-1.17.0        | 430 KB    | 3          |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nreadline-8.3         | 471 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibxcb-1.17.0        | 430 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\nlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \u001b[A\u001b[A\n\npython-3.11.14       | 29.8 MB   | #######    |  70% \u001b[A\u001b[A.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpat-2.7.1          | 182 KB    | 8          |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbzip2-1.0.8          | 262 KB    | 6          |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpat-2.7.1          | 182 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\npython-3.11.14       | 29.8 MB   | ########   |  81% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npython-3.11.14       | 29.8 MB   | #########5 |  96% A\n\n\u001b[A\u001b[A\npython-3.11.14       | 29.8 MB   | ########## | 100% \u001b[A\n\n\n\ntk-8.6.15            | 3.4 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nsetuptools-80.9.0    | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nsetuptools-80.9.0    | 1.9 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\npip-25.2             | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nsqlite-3.50.2        | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\nld_impl_linux-64-2.4 | 672 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nxorg-libx11-1.8.12   | 895 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nxorg-libx11-1.8.12   | 895 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nxorg-xorgproto-2024. | 580 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nxorg-xorgproto-2024. | 580 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\nxz-5.6.4             | 567 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\nxz-5.6.4             | 567 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nreadline-8.3         | 471 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nreadline-8.3         | 471 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpat-2.7.1          | 182 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpat-2.7.1          | 182 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbzip2-1.0.8          | 262 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibxcb-1.17.0        | 430 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwheel-0.45.1         | 151 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\nlibgomp-11.2.0       | 474 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\nlibgomp-11.2.0       | 474 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nncurses-6.5          | 1.1 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\npython-3.11.14       | 29.8 MB   | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                     A\u001b[A\n                                                     \u001b[A\n\n                                                     \u001b[A\u001b[A\n\n\n                                                     \u001b[A\u001b[A\u001b[A\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\u001b[A\n\n\u001b[A\u001b[A\n\n\n\u001b[A\u001b[A\u001b[A\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\nPreparing transaction: done\nVerifying transaction: |done\nExecuting transaction: done\nInstalling pip dependencies: |-|/\\/\\/\\\\ Ran pip subprocess with arguments:\n['/opt/miniconda/envs/inf-conda-env/bin/python', '-m', 'pip', 'install', '-U', '-r', '/var/azureml-app/condaenv.vekhl2_y.requirements.txt', '--exists-action=b']\nPip subprocess output:\nCollecting scikit-learn (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 1))\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nCollecting pandas (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 2))\n  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\nCollecting numpy (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 3))\n  Downloading numpy-2.3.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\nCollecting nltk (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 4))\n  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting joblib (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 5))\n  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\nCollecting azureml-mlflow (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading azureml_mlflow-1.60.0.post1-py3-none-any.whl.metadata (2.8 kB)\nCollecting matplotlib (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 7))\n  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nCollecting azure-ai-ml (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading azure_ai_ml-1.30.0-py3-none-any.whl.metadata (40 kB)\nCollecting azure-identity (from -r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 9))\n  Downloading azure_identity-1.25.1-py3-none-any.whl.metadata (88 kB)\nCollecting scipy>=1.8.0 (from scikit-learn->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 1))\n  Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 1))\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nCollecting python-dateutil>=2.8.2 (from pandas->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 2))\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting pytz>=2020.1 (from pandas->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 2))\n  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting tzdata>=2022.7 (from pandas->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 2))\n  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting click (from nltk->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 4))\n  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting regex>=2021.8.3 (from nltk->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 4))\n  Downloading regex-2025.10.23-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\nCollecting tqdm (from nltk->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 4))\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nCollecting jsonpickle<5.0.0 (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\nCollecting mlflow-skinny<3.0.0 (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading mlflow_skinny-2.22.2-py3-none-any.whl.metadata (31 kB)\nCollecting msrest>=0.6.18 (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\nCollecting azure-core!=1.22.0,<2.0.0,>=1.8.0 (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading azure_core-1.36.0-py3-none-any.whl.metadata (47 kB)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0 (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading azure_mgmt_core-1.6.0-py3-none-any.whl.metadata (4.6 kB)\nCollecting azure-storage-blob<=12.19.0,>=12.5.0 (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\nCollecting azure-common<2.0.0,>=1.1 (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\nCollecting cryptography (from azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\nCollecting requests>=2.21.0 (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\nCollecting typing-extensions>=4.6.0 (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting isodate>=0.6.1 (from azure-storage-blob<=12.19.0,>=12.5.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\nCollecting cachetools<6,>=5.0.0 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting cloudpickle<4 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading databricks_sdk-0.71.0-py3-none-any.whl.metadata (39 kB)\nCollecting fastapi<1 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading fastapi-0.120.2-py3-none-any.whl.metadata (28 kB)\nCollecting gitpython<4,>=3.1.9 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting packaging<25 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting protobuf<7,>=3.12.0 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nCollecting pydantic<3,>=1.10.8 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\nCollecting pyyaml<7,>=5.1 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\nCollecting sqlparse<1,>=0.4.0 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting uvicorn<1 (from mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading google_auth-2.42.1-py2.py3-none-any.whl.metadata (6.6 kB)\nCollecting starlette<0.50.0,>=0.40.0 (from fastapi<1->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading starlette-0.49.1-py3-none-any.whl.metadata (6.4 kB)\nCollecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\nCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\nCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting annotated-types>=0.6.0 (from pydantic<3,>=1.10.8->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.41.4 (from pydantic<3,>=1.10.8->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading pydantic_core-2.41.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\nCollecting typing-inspection>=0.4.2 (from pydantic<3,>=1.10.8->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\nCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 2))\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting charset_normalizer<4,>=2 (from requests>=2.21.0->azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\nCollecting idna<4,>=2.5 (from requests>=2.21.0->azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\nCollecting urllib3<3,>=1.21.1 (from requests>=2.21.0->azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting certifi>=2017.4.17 (from requests>=2.21.0->azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\nCollecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\nCollecting anyio<5,>=3.6.2 (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\nCollecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting h11>=0.8 (from uvicorn<1->mlflow-skinny<3.0.0->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nCollecting contourpy>=1.0.1 (from matplotlib->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 7))\n  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\nCollecting cycler>=0.10 (from matplotlib->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 7))\n  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting fonttools>=4.22.0 (from matplotlib->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 7))\n  Downloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\nCollecting kiwisolver>=1.3.1 (from matplotlib->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 7))\n  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\nCollecting pillow>=8 (from matplotlib->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 7))\n  Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\nCollecting pyparsing>=3 (from matplotlib->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 7))\n  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\nCollecting marshmallow<4.0.0,>=3.5 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\nCollecting jsonschema<5.0.0,>=4.0.0 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\nCollecting strictyaml<2.0.0 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\nCollecting colorama<1.0.0 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\nCollecting pyjwt<3.0.0 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\nCollecting azure-storage-file-share (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading azure_storage_file_share-12.23.1-py3-none-any.whl.metadata (52 kB)\nCollecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading azure_storage_file_datalake-12.22.0-py3-none-any.whl.metadata (16 kB)\nCollecting pydash<9.0.0,>=6.0.0 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\nCollecting azure-monitor-opentelemetry (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading azure_monitor_opentelemetry-1.8.1-py3-none-any.whl.metadata (23 kB)\nCollecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading rpds_py-0.28.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nCollecting msal>=1.30.0 (from azure-identity->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 9))\n  Downloading msal-1.34.0-py3-none-any.whl.metadata (11 kB)\nCollecting msal-extensions>=1.2.0 (from azure-identity->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 9))\n  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\nINFO: pip is looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\nCollecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading azure_storage_file_datalake-12.21.0-py3-none-any.whl.metadata (16 kB)\n  Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl.metadata (16 kB)\n  Downloading azure_storage_file_datalake-12.19.0-py3-none-any.whl.metadata (16 kB)\n  Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl.metadata (16 kB)\n  Downloading azure_storage_file_datalake-12.18.0-py3-none-any.whl.metadata (16 kB)\n  Downloading azure_storage_file_datalake-12.17.0-py3-none-any.whl.metadata (16 kB)\n  Downloading azure_storage_file_datalake-12.16.0-py3-none-any.whl.metadata (15 kB)\nINFO: pip is still looking at multiple versions of azure-storage-file-datalake to determine which version is compatible with other requirements. This could take a while.\n  Downloading azure_storage_file_datalake-12.15.0-py3-none-any.whl.metadata (15 kB)\n  Downloading azure_storage_file_datalake-12.14.0-py3-none-any.whl.metadata (15 kB)\nCollecting cffi>=2.0.0 (from cryptography->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\nCollecting pycparser (from cffi>=2.0.0->cryptography->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\nCollecting requests-oauthlib>=0.5.0 (from msrest>=0.6.18->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\nCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azureml-mlflow->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 6))\n  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\nCollecting azure-core-tracing-opentelemetry~=1.0.0b11 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl.metadata (11 kB)\nCollecting azure-monitor-opentelemetry-exporter~=1.0.0b41 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading azure_monitor_opentelemetry_exporter-1.0.0b44-py2.py3-none-any.whl.metadata (33 kB)\nCollecting opentelemetry-instrumentation-django~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_django-0.59b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-instrumentation-fastapi~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-instrumentation-flask~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_flask-0.59b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-instrumentation-psycopg2~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_psycopg2-0.59b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation-requests~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl.metadata (2.6 kB)\nCollecting opentelemetry-instrumentation-urllib~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_urllib-0.59b0-py3-none-any.whl.metadata (3.4 kB)\nCollecting opentelemetry-instrumentation-urllib3~=0.57b0 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_urllib3-0.59b0-py3-none-any.whl.metadata (4.2 kB)\nCollecting opentelemetry-resource-detector-azure~=0.1.5 (from azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl.metadata (5.3 kB)\nCollecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter~=1.0.0b41->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\nCollecting psutil<8,>=5.9 (from azure-monitor-opentelemetry-exporter~=1.0.0b41->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\nCollecting opentelemetry-instrumentation-wsgi==0.59b0 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_wsgi-0.59b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\nCollecting opentelemetry-util-http==0.59b0 (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_util_http-0.59b0-py3-none-any.whl.metadata (2.6 kB)\nCollecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\nCollecting opentelemetry-instrumentation-asgi==0.59b0 (from opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.59b0->opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading asgiref-3.10.0-py3-none-any.whl.metadata (9.3 kB)\nCollecting opentelemetry-instrumentation-dbapi==0.59b0 (from opentelemetry-instrumentation-psycopg2~=0.57b0->azure-monitor-opentelemetry->azure-ai-ml->-r /var/azureml-app/condaenv.vekhl2_y.requirements.txt (line 8))\n  Downloading opentelemetry_instrumentation_dbapi-0.59b0-py3-none-any.whl.metadata (2.0 kB)\nDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.7/9.7 MB 125.8 MB/s  0:00:00\nDownloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 133.3 MB/s  0:00:00\nDownloading numpy-2.3.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.9/16.9 MB 155.9 MB/s  0:00:00\nDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 51.6 MB/s  0:00:00\nDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\nDownloading azureml_mlflow-1.60.0.post1-py3-none-any.whl (1.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 38.8 MB/s  0:00:00\nDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nDownloading azure_core-1.36.0-py3-none-any.whl (213 kB)\nDownloading azure_mgmt_core-1.6.0-py3-none-any.whl (29 kB)\nDownloading azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\nDownloading jsonpickle-4.1.1-py3-none-any.whl (47 kB)\nDownloading mlflow_skinny-2.22.2-py3-none-any.whl (6.3 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 140.0 MB/s  0:00:00\nDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading click-8.3.0-py3-none-any.whl (107 kB)\nDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\nDownloading databricks_sdk-0.71.0-py3-none-any.whl (752 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 752.6/752.6 kB 29.7 MB/s  0:00:00\nDownloading fastapi-0.120.2-py3-none-any.whl (108 kB)\nDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\nDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\nDownloading google_auth-2.42.1-py2.py3-none-any.whl (222 kB)\nDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\nDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\nDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\nDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\nDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\nDownloading pydantic-2.12.3-py3-none-any.whl (462 kB)\nDownloading pydantic_core-2.41.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 89.4 MB/s  0:00:00\nDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\nDownloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 806.6/806.6 kB 35.0 MB/s  0:00:00\nDownloading requests-2.32.5-py3-none-any.whl (64 kB)\nDownloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\nDownloading idna-3.11-py3-none-any.whl (71 kB)\nDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\nDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\nDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\nDownloading starlette-0.49.1-py3-none-any.whl (74 kB)\nDownloading anyio-4.11.0-py3-none-any.whl (109 kB)\nDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\nDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\nDownloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\nDownloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.7/8.7 MB 174.8 MB/s  0:00:00\nDownloading azure_ai_ml-1.30.0-py3-none-any.whl (13.3 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.3/13.3 MB 79.2 MB/s  0:00:00\nDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\nDownloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\nDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\nDownloading pydash-8.0.5-py3-none-any.whl (102 kB)\nDownloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\nDownloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\nDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nDownloading azure_identity-1.25.1-py3-none-any.whl (191 kB)\nDownloading annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\nDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading attrs-25.4.0-py3-none-any.whl (67 kB)\nDownloading azure_storage_file_datalake-12.14.0-py3-none-any.whl (251 kB)\nDownloading certifi-2025.10.5-py3-none-any.whl (163 kB)\nDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\nDownloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 100.6 MB/s  0:00:00\nDownloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)\nDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nDownloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 126.0 MB/s  0:00:00\nDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nDownloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\nDownloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 43.7 MB/s  0:00:00\nDownloading msal-1.34.0-py3-none-any.whl (116 kB)\nDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\nDownloading msrest-0.7.1-py3-none-any.whl (85 kB)\nDownloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 160.7 MB/s  0:00:00\nDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\nDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\nDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\nDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\nDownloading referencing-0.37.0-py3-none-any.whl (26 kB)\nDownloading regex-2025.10.23-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 800.3/800.3 kB 31.9 MB/s  0:00:00\nDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\nDownloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\nDownloading rpds_py-0.28.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (382 kB)\nDownloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━���━━━━━━━━ 35.9/35.9 MB 90.3 MB/s  0:00:00\nDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\nDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\nDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\nDownloading azure_monitor_opentelemetry-1.8.1-py3-none-any.whl (27 kB)\nDownloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\nDownloading azure_monitor_opentelemetry_exporter-1.0.0b44-py2.py3-none-any.whl (198 kB)\nDownloading fixedint-0.1.6-py3-none-any.whl (12 kB)\nDownloading opentelemetry_instrumentation_django-0.59b0-py3-none-any.whl (19 kB)\nDownloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\nDownloading opentelemetry_instrumentation_wsgi-0.59b0-py3-none-any.whl (14 kB)\nDownloading opentelemetry_util_http-0.59b0-py3-none-any.whl (7.6 kB)\nDownloading opentelemetry_instrumentation_fastapi-0.59b0-py3-none-any.whl (13 kB)\nDownloading opentelemetry_instrumentation_asgi-0.59b0-py3-none-any.whl (16 kB)\nDownloading asgiref-3.10.0-py3-none-any.whl (24 kB)\nDownloading opentelemetry_instrumentation_flask-0.59b0-py3-none-any.whl (14 kB)\nDownloading opentelemetry_instrumentation_psycopg2-0.59b0-py3-none-any.whl (10 kB)\nDownloading opentelemetry_instrumentation_dbapi-0.59b0-py3-none-any.whl (13 kB)\nDownloading opentelemetry_instrumentation_requests-0.59b0-py3-none-any.whl (12 kB)\nDownloading opentelemetry_instrumentation_urllib-0.59b0-py3-none-any.whl (12 kB)\nDownloading opentelemetry_instrumentation_urllib3-0.59b0-py3-none-any.whl (13 kB)\nDownloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\nDownloading psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (258 kB)\nDownloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (82 kB)\nDownloading azure_storage_file_share-12.23.1-py3-none-any.whl (307 kB)\nDownloading pycparser-2.23-py3-none-any.whl (118 kB)\nInstalling collected packages: pytz, fixedint, azure-common, zipp, wrapt, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sqlparse, sniffio, smmap, six, rpds-py, regex, pyyaml, pyparsing, pyjwt, pycparser, pyasn1, psutil, protobuf, pillow, packaging, opentelemetry-util-http, oauthlib, numpy, kiwisolver, jsonpickle, joblib, isodate, idna, h11, fonttools, cycler, colorama, cloudpickle, click, charset_normalizer, certifi, cachetools, attrs, asgiref, annotated-types, annotated-doc, uvicorn, typing-inspection, scipy, rsa, requests, referencing, python-dateutil, pydash, pydantic-core, pyasn1-modules, nltk, marshmallow, importlib_metadata, gitdb, contourpy, cffi, anyio, strictyaml, starlette, scikit-learn, requests-oauthlib, pydantic, pandas, opentelemetry-api, matplotlib, jsonschema-specifications, google-auth, gitpython, cryptography, azure-core, opentelemetry-semantic-conventions, msrest, jsonschema, fastapi, databricks-sdk, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, azure-core-tracing-opentelemetry, opentelemetry-sdk, opentelemetry-instrumentation, msal, azure-storage-file-datalake, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, msal-extensions, mlflow-skinny, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, azure-identity, azureml-mlflow, azure-monitor-opentelemetry-exporter, azure-monitor-opentelemetry, azure-ai-ml\n\nSuccessfully installed annotated-doc-0.0.3 annotated-types-0.7.0 anyio-4.11.0 asgiref-3.10.0 attrs-25.4.0 azure-ai-ml-1.30.0 azure-common-1.1.28 azure-core-1.36.0 azure-core-tracing-opentelemetry-1.0.0b12 azure-identity-1.25.1 azure-mgmt-core-1.6.0 azure-monitor-opentelemetry-1.8.1 azure-monitor-opentelemetry-exporter-1.0.0b44 azure-storage-blob-12.19.0 azure-storage-file-datalake-12.14.0 azure-storage-file-share-12.23.1 azureml-mlflow-1.60.0.post1 cachetools-5.5.2 certifi-2025.10.5 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.0 cloudpickle-3.1.1 colorama-0.4.6 contourpy-1.3.3 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.71.0 fastapi-0.120.2 fixedint-0.1.6 fonttools-4.60.1 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.42.1 h11-0.16.0 idna-3.11 importlib_metadata-8.7.0 isodate-0.7.2 joblib-1.5.2 jsonpickle-4.1.1 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 marshmallow-3.26.1 matplotlib-3.10.7 mlflow-skinny-2.22.2 msal-1.34.0 msal-extensions-1.3.1 msrest-0.7.1 nltk-3.9.2 numpy-2.3.4 oauthlib-3.3.1 opentelemetry-api-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-asgi-0.59b0 opentelemetry-instrumentation-dbapi-0.59b0 opentelemetry-instrumentation-django-0.59b0 opentelemetry-instrumentation-fastapi-0.59b0 opentelemetry-instrumentation-flask-0.59b0 opentelemetry-instrumentation-psycopg2-0.59b0 opentelemetry-instrumentation-requests-0.59b0 opentelemetry-instrumentation-urllib-0.59b0 opentelemetry-instrumentation-urllib3-0.59b0 opentelemetry-instrumentation-wsgi-0.59b0 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 opentelemetry-util-http-0.59b0 packaging-24.2 pandas-2.3.3 pillow-12.0.0 protobuf-6.33.0 psutil-7.1.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.12.3 pydantic-core-2.41.4 pydash-8.0.5 pyjwt-2.10.1 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 regex-2025.10.23 requests-2.32.5 requests-oauthlib-2.0.0 rpds-py-0.28.0 rsa-4.9.1 scikit-learn-1.7.2 scipy-1.16.3 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 sqlparse-0.5.3 starlette-0.49.1 strictyaml-1.7.3 threadpoolctl-3.6.0 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.38.0 wrapt-1.17.3 zipp-3.23.0\n\ndone\n#\n# To activate this environment, use\n#\n#     $ conda activate inf-conda-env\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n....... ---> 61732f454139\nStep 6/7 : RUN conda run -n inf-conda-env pip install debugpy\n ---> Running in 2c2a5abe272f\n.Collecting debugpy\n  Downloading debugpy-1.8.17-cp311-cp311-manylinux_2_34_x86_64.whl.metadata (1.4 kB)\nDownloading debugpy-1.8.17-cp311-cp311-manylinux_2_34_x86_64.whl (3.2 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 63.1 MB/s  0:00:00\nInstalling collected packages: debugpy\nSuccessfully installed debugpy-1.8.17\n\n ---> 6eb939db4d64\nStep 7/7 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n. ---> Running in 507eab16580d\n ---> 245379c09f2a\nSuccessfully built 245379c09f2a\nSuccessfully tagged endpoint-10301809734550:blue\n\nStarting up endpointDone (1m 50s)\n"
        },
        {
          "output_type": "error",
          "ename": "APIError",
          "evalue": "500 Server Error for http+docker://localhost/v1.43/containers/create?name=endpoint-10301809734550.blue: Internal Server Error (\"invalid volume specification: '/mnt/batch/tasks/shared/LS_root/mounts/clusters/zunku-comp-instance/code/Users/azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourcegroups/brazilian-ecommerce-sentiment-analysis/workspaces/sentiment-analysis/datastores/workspaceblobstore/paths/LocalUpload/9f085b74e59e1f12b8dd911b365c4d3b0ab8ffe94d65ef1b49e9fb6fc8490f5c:/var/azureml-app/azureml-models//sentiment-classifier/1:z'\")",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/docker/api/client.py:275\u001b[0m, in \u001b[0;36mAPIClient._raise_for_status\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: http+docker://localhost/v1.43/containers/create?name=endpoint-10301809734550.blue",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[59], line 18\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# create a local online endpoint\u001b[39;00m\n\u001b[1;32m      5\u001b[0m blue_deployment \u001b[38;5;241m=\u001b[39m ManagedOnlineDeployment(\n\u001b[1;32m      6\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     endpoint_name\u001b[38;5;241m=\u001b[39monline_endpoint_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_deployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblue_deployment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvscode_debug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:138\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    137\u001b[0m                 span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:288\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(ACTIVITY_SPAN):\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    286\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    287\u001b[0m         ):\n\u001b[0;32m--> 288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:218\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_online_deployment_operations.py:144\u001b[0m, in \u001b[0;36mOnlineDeploymentOperations.begin_create_or_update\u001b[0;34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m LocalDeploymentGPUNotAvailable(\n\u001b[1;32m    139\u001b[0m                 msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    140\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNvidia GPU is not available in your local system.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use nvidia-smi command to see the available GPU\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m                 )\n\u001b[1;32m    143\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_deployment_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_local_endpoint_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvscode_debug\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deployment \u001b[38;5;129;01mand\u001b[39;00m deployment\u001b[38;5;241m.\u001b[39minstance_type \u001b[38;5;129;01mand\u001b[39;00m deployment\u001b[38;5;241m.\u001b[39minstance_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m SmallSKUs:\n\u001b[1;32m    150\u001b[0m     module_logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m may be too small for compute resources. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: \u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://learn.microsoft.com/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m         deployment\u001b[38;5;241m.\u001b[39minstance_type,\n\u001b[1;32m    155\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_local_deployment_helper.py:105\u001b[0m, in \u001b[0;36m_LocalDeploymentHelper.create_or_update\u001b[0;34m(self, deployment, local_endpoint_mode, local_enable_gpu)\u001b[0m\n\u001b[1;32m    103\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_local_deployment_helper.py:90\u001b[0m, in \u001b[0;36m_LocalDeploymentHelper.create_or_update\u001b[0;34m(self, deployment, local_endpoint_mode, local_enable_gpu)\u001b[0m\n\u001b[1;32m     84\u001b[0m     deployment_metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(deployment\u001b[38;5;241m.\u001b[39m_to_dict())\n\u001b[1;32m     85\u001b[0m     endpoint_metadata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     86\u001b[0m         endpoint_metadata\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m endpoint_metadata\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m _get_stubbed_endpoint_metadata(endpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(deployment\u001b[38;5;241m.\u001b[39mendpoint_name))\n\u001b[1;32m     89\u001b[0m     )\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mlocal_endpoint_polling_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_deployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moperation_message\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m / \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m) \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(endpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(deployment\u001b[38;5;241m.\u001b[39mendpoint_name), deployment_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(deployment\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=W0718\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_endpoint_utils.py:103\u001b[0m, in \u001b[0;36mlocal_endpoint_polling_wrapper\u001b[0;34m(func, message, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m event \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39msubmit(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    102\u001b[0m polling_wait(poller\u001b[38;5;241m=\u001b[39mevent, start_time\u001b[38;5;241m=\u001b[39mstart_time, message\u001b[38;5;241m=\u001b[39mmessage, is_local\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_local_deployment_helper.py:300\u001b[0m, in \u001b[0;36m_LocalDeploymentHelper._create_deployment\u001b[0;34m(self, endpoint_name, deployment, local_endpoint_mode, local_enable_gpu, endpoint_metadata, deployment_metadata)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# Determine whether we need to use local context or downloaded context\u001b[39;00m\n\u001b[1;32m    299\u001b[0m build_directory \u001b[38;5;241m=\u001b[39m downloaded_build_context \u001b[38;5;28;01mif\u001b[39;00m downloaded_build_context \u001b[38;5;28;01melse\u001b[39;00m deployment_directory\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_docker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_deployment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdockerfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_byoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdockerfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconda_source_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myaml_env_conda_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconda_yaml_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myaml_env_conda_file_contents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolumes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvolumes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mazureml_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring_route\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_byoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mLocalEndpointConstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDOCKER_PORT\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprebuilt_image_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myaml_base_image_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_byoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_local_endpoints/docker_client.py:196\u001b[0m, in \u001b[0;36mDockerClient.create_deployment\u001b[0;34m(self, endpoint_name, deployment_name, endpoint_metadata, deployment_metadata, build_directory, dockerfile_path, conda_source_path, conda_yaml_contents, volumes, environment, azureml_port, local_endpoint_mode, prebuilt_image_name, local_enable_gpu)\u001b[0m\n\u001b[1;32m    194\u001b[0m container_name \u001b[38;5;241m=\u001b[39m _get_container_name(endpoint_name, deployment_name)\n\u001b[1;32m    195\u001b[0m device_requests \u001b[38;5;241m=\u001b[39m [docker\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mDeviceRequest(count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, capabilities\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m]])] \u001b[38;5;28;01mif\u001b[39;00m local_enable_gpu \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m container \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolumes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reformat_volumes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolumes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpublish_all_ports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_requests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_requests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_endpoint_mode \u001b[38;5;241m==\u001b[39m LocalEndpointMode\u001b[38;5;241m.\u001b[39mVSCodeDevContainer:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/docker/models/containers.py:935\u001b[0m, in \u001b[0;36mContainerCollection.create\u001b[0;34m(self, image, command, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39m_version\n\u001b[1;32m    934\u001b[0m create_kwargs \u001b[38;5;241m=\u001b[39m _create_container_args(kwargs)\n\u001b[0;32m--> 935\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_container\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcreate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/docker/api/container.py:440\u001b[0m, in \u001b[0;36mContainerApiMixin.create_container\u001b[0;34m(self, image, command, hostname, user, detach, stdin_open, tty, ports, environment, volumes, network_disabled, name, entrypoint, working_dir, domainname, host_config, mac_address, labels, stop_signal, networking_config, healthcheck, stop_timeout, runtime, use_config_proxy, platform)\u001b[0m\n\u001b[1;32m    428\u001b[0m     environment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxy_configs\u001b[38;5;241m.\u001b[39minject_proxy_environment(\n\u001b[1;32m    429\u001b[0m         environment\n\u001b[1;32m    430\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    432\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_container_config(\n\u001b[1;32m    433\u001b[0m     image, command, hostname, user, detach, stdin_open, tty,\n\u001b[1;32m    434\u001b[0m     ports, environment, volumes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m     stop_timeout, runtime\n\u001b[1;32m    439\u001b[0m )\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_container_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplatform\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/docker/api/container.py:457\u001b[0m, in \u001b[0;36mContainerApiMixin.create_container_from_config\u001b[0;34m(self, config, name, platform)\u001b[0m\n\u001b[1;32m    455\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplatform\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m platform\n\u001b[1;32m    456\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_json(u, data\u001b[38;5;241m=\u001b[39mconfig, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/docker/api/client.py:281\u001b[0m, in \u001b[0;36mAPIClient._result\u001b[0;34m(self, response, json, binary)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, response, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (json \u001b[38;5;129;01mand\u001b[39;00m binary)\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m json:\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/docker/api/client.py:277\u001b[0m, in \u001b[0;36mAPIClient._raise_for_status\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    275\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mcreate_api_error_from_http_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/docker/errors.py:39\u001b[0m, in \u001b[0;36mcreate_api_error_from_http_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m NotFound\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(e, response\u001b[38;5;241m=\u001b[39mresponse, explanation\u001b[38;5;241m=\u001b[39mexplanation) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mAPIError\u001b[0m: 500 Server Error for http+docker://localhost/v1.43/containers/create?name=endpoint-10301809734550.blue: Internal Server Error (\"invalid volume specification: '/mnt/batch/tasks/shared/LS_root/mounts/clusters/zunku-comp-instance/code/Users/azureml:/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourcegroups/brazilian-ecommerce-sentiment-analysis/workspaces/sentiment-analysis/datastores/workspaceblobstore/paths/LocalUpload/9f085b74e59e1f12b8dd911b365c4d3b0ab8ffe94d65ef1b49e9fb6fc8490f5c:/var/azureml-app/azureml-models//sentiment-classifier/1:z'\")"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1761851973859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# blue deployment takes 100 traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-10301809734550.eastus.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-10301809734550.eastus.inference.ml.azure.com/swagger.json', 'name': 'endpoint-10301809734550', 'description': 'Online endpoint for MLflow sentiment classifier model', 'tags': {}, 'properties': {'createdBy': 'Daniel Mendez', 'createdAt': '2025-10-30T18:09:51.775509+0000', 'lastModifiedAt': '2025-10-30T18:38:50.555314+0000', 'azureml.onlineendpointid': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourcegroups/brazilian-ecommerce-sentiment-analysis/providers/microsoft.machinelearningservices/workspaces/sentiment-analysis/onlineendpoints/endpoint-10301809734550', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oeidp:280e7043-048d-45b7-949c-f536b1ed03f3:b3148ad4-96cb-4dce-9daa-4be3e7458af6?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/a4fd359b-aa4a-4e0c-a8b2-338ed69a1d51/resourceGroups/brazilian-ecommerce-sentiment-analysis/providers/Microsoft.MachineLearningServices/workspaces/sentiment-analysis/onlineEndpoints/endpoint-10301809734550', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/zunku-comp-instance/code/Users', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7722e07d45e0>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7722e0553f70>, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1761849623098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\n",
        "response = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=\"blue\",\n",
        "    request_file=\"sample-data.json\",\n",
        ")\n",
        "\n",
        "if response[1]=='1':\n",
        "    print(\"Diabetic\")\n",
        "else:\n",
        "    print (\"Not diabetic\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}